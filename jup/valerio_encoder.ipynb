{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groundwork for autoencoder class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Autoencoder:\n",
    "    '''\n",
    "    Autoencoder representes a Deep Convolutional autoencoder architecture with mirrored\n",
    "    encoder and decoder components.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                input_shape,\n",
    "                conv_filters,\n",
    "                conv_kernels,\n",
    "                conv_strides,\n",
    "                latent_space_dim):\n",
    "        self.input_shape = input_shape # [28, 28, 1] \n",
    "        self.conv_filters = conv_filters # [2, 4, 8] \n",
    "        self.conv_kernels = conv_kernels # [3, 5, 3] # square kernel size\n",
    "        self.conv_strides = conv_strides #, [1, 2, 2]\n",
    "        self.latent_space_dim = latent_space_dim # 2\n",
    "        \n",
    "        self.encoder = None # will be keras\n",
    "        self.decoder = None # will be keras\n",
    "        self.model = None # willl be keras\n",
    "        \n",
    "        # private attributes\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        msc_loss = MeanSquaredError()\n",
    "        self.model.compile(optimizer=optimizer, loss=msc_loss)\n",
    "\n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train, x_train, batch_size=batch_size, epochs=num_epochs, shuffle=True)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "        \n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
    "        return output_layer\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "    \n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # wLe want the same as before... BUT... flattened\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input) # don't for get last part\n",
    "        return dense_layer\n",
    "    \n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "    \n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        '''\n",
    "        add conv transpose blocks.\n",
    "        '''\n",
    "        # loop through the conv layers in reverse\n",
    "\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            # [ 0, 1, 2] must be reversed... and get rid of first index --> [2,1]\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "\n",
    "        return x \n",
    "    \n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "            \n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_ReLU_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "    \n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        '''\n",
    "        creates all convolutional blocks in an encoder\n",
    "        '''\n",
    "\n",
    "        x = encoder_input # graph of 'notes that count'\n",
    "\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        '''\n",
    "        interesting thing: adds a convolutional block to a graph of layers consisting of\n",
    "        conv2d + ReLU + batch_normalization.\n",
    "        '''\n",
    "\n",
    "        layer_number = layer_index+1\n",
    "\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        '''\n",
    "        Flatten data and add bottleneck (Dense Layer).\n",
    "        '''\n",
    "\n",
    "        #store infromation for decoder stage (mirroring)\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:] # [2, 7, 7] e.g.Batch size [0] not interesting\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(self.latent_space_dim, name=\"encoder_output\")(x) # an int for number of neurons\n",
    "        return x\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_1 (Conv2D (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "encoder_relu_1 (ReLU)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_2 (Conv2D (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "encoder_relu_2 (ReLU)        (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_3 (Conv2D (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "encoder_relu_3 (ReLU)        (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_3 (BatchNormaliza (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_4 (Conv2D (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "encoder_relu_4 (ReLU)        (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_4 (BatchNormaliza (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "=================================================================\n",
      "Total params: 99,842\n",
      "Trainable params: 99,394\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "decoder_dense (Dense)        (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "decoder_ReLU_1 (ReLU)        (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_ReLU_2 (ReLU)        (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_ReLU_3 (ReLU)        (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_3 (BatchNormaliza (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "sigmoid_layer (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 121,537\n",
      "Trainable params: 121,153\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 99842     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         121537    \n",
      "=================================================================\n",
      "Total params: 221,379\n",
      "Trainable params: 220,547\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a = Autoencoder(input_shape=[28,28, 1],\n",
    "               conv_filters=[32,64,64,64],\n",
    "               conv_kernels=[3,3,3,3],\n",
    "               conv_strides=[1,2,2,1],\n",
    "               latent_space_dim=2)\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
